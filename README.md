# Benchmark as of now

### Benchmarking model: NbAiLab/nb-sbert-base
Results:
- Language: ENG - Recall@5: 0.650, MRR@5: 0.588
- Language: NO - Recall@5: 0.850, MRR@5: 0.800
- Language: overall - Recall@5: 0.750, MRR@5: 0.694

### Benchmarking model: sentence-transformers/all-MiniLM-L6-v2
Results:
- Language: ENG - Recall@5: 0.600, MRR@5: 0.446
- Language: NO - Recall@5: 0.650, MRR@5: 0.600
- Language: overall - Recall@5: 0.625, MRR@5: 0.523

### Benchmarking model: abhinand/MedEmbed-large-v0.1
Results:
- Language: ENG - Recall@5: 0.650, MRR@5: 0.613
- Language: NO - Recall@5: 0.750, MRR@5: 0.725
- Language: overall - Recall@5: 0.700, MRR@5: 0.669

### Benchmarking model: vesteinn/ScandiBERT
Results:
- Language: ENG - Recall@5: 0.300, MRR@5: 0.300
- Language: NO - Recall@5: 0.500, MRR@5: 0.420
- Language: overall - Recall@5: 0.400, MRR@5: 0.360
